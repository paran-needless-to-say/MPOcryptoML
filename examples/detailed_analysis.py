"""
ìƒì„¸ ë¶„ì„: ì‚¬ê¸° ì§€ê°‘ íŒì • ë° í”¼ì³ ë¶„ì„
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent / "src"))

import json
import pandas as pd
import numpy as np
from graph import CryptoTransactionGraph
from ppr import PersonalizedPageRank
from scoring import NormalizedScorer
from anomaly_detector import MPOCryptoMLDetector
from tqdm import tqdm


def detailed_analysis():
    print("="*70)
    print("ğŸ“Š ìƒì„¸ ë¶„ì„: ì‚¬ê¸° ì§€ê°‘ íŒì • ë° í”¼ì³ ë¶„ì„")
    print("="*70)
    
    # 1. ê·¸ë˜í”„ ë¡œë“œ
    print("\n[Step 1] Loading graph...")
    filepath = "results/graph_200_etherscan_real.json"
    
    graph_obj = CryptoTransactionGraph()
    with open(filepath, 'r') as f:
        data = json.load(f)
        graph_obj.nodes = data['nodes']
        graph_obj.edges = [(e['from'], e['to'], e['value'], e['timestamp']) for e in data['edges']]
        graph_obj.node_labels = {k: int(v) for k, v in data['labels'].items()}
    
    # ì‹¤ì œ ì‚¬ê¸° ì§€ê°‘ ê°œìˆ˜
    total_anomalies = sum(graph_obj.node_labels.values())
    total_nodes = len(graph_obj.node_labels)
    total_normal = total_nodes - total_anomalies
    
    print(f"  ì´ ë…¸ë“œ: {total_nodes}")
    print(f"  ì‹¤ì œ ì‚¬ê¸° ì§€ê°‘: {total_anomalies}ê°œ")
    print(f"  ì •ìƒ ì§€ê°‘: {total_normal}ê°œ")
    
    # 2. PPR ê³„ì‚°
    print("\n[Step 2] Computing PPR...")
    graph = graph_obj.build_graph()
    ppr = PersonalizedPageRank(graph, alpha=0.5, epsilon=0.01, p_f=1.0)
    
    source_nodes = ppr.get_source_nodes()
    if len(source_nodes) == 0:
        source_nodes = set(graph_obj.nodes[:20])
    
    sample_nodes = list(source_nodes)[:min(10, len(source_nodes))]
    
    ppr_results = {}
    ppr_scores_dict = {}
    
    print(f"  Computing PPR for {len(sample_nodes)} source nodes...")
    for node in tqdm(sample_nodes, desc="  PPR", ncols=70):
        sps, svn, all_nodes_list = ppr.compute_single_source_ppr(node)
        ppr_results[node] = svn
        ppr_scores_dict[node] = (sps, all_nodes_list)
    
    # 3. Feature ê³„ì‚°
    print("\n[Step 3] Computing features...")
    scorer = NormalizedScorer(graph_obj, ppr_results)
    feature_scores = scorer.compute_all_scores()
    
    # 4. Anomaly Detection
    print("\n[Step 4] Training model and computing scores...")
    full_ppr_scores = {}
    for source in ppr_scores_dict.keys():
        full_ppr_scores[source] = ppr_scores_dict[source]
    
    detector = MPOCryptoMLDetector(
        ppr_scores=full_ppr_scores,
        feature_scores=feature_scores,
        labels=graph_obj.node_labels
    )
    
    detector.train_logistic_regression()
    detector.compute_anomaly_scores()
    detector.compute_pattern_scores()
    
    # 5. ìƒì„¸ ë¶„ì„
    print("\n" + "="*70)
    print("ğŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    print("="*70)
    
    results_df = detector.get_results_df()
    results_df_sorted = results_df.sort_values('anomaly_score', ascending=False)
    
    print(f"\n[1] ì‹¤ì œ ì‚¬ê¸° ì§€ê°‘ í˜„í™©:")
    print(f"  ì´ ì‚¬ê¸° ì§€ê°‘: {total_anomalies}ê°œ ({total_anomalies/total_nodes*100:.2f}%)")
    print(f"  ì´ ì •ìƒ ì§€ê°‘: {total_normal}ê°œ ({total_normal/total_nodes*100:.2f}%)")
    
    # Top K ë¶„ì„
    print(f"\n[2] ëª¨ë¸ íŒì • ê²°ê³¼:")
    for k in [5, 10, 20, 50]:
        top_k = results_df_sorted.head(k)
        detected_anomalies = top_k[top_k['label'] == 1]
        precision = len(detected_anomalies) / k
        recall = len(detected_anomalies) / total_anomalies if total_anomalies > 0 else 0
        
        print(f"  Top {k}:")
        print(f"    ê°ì§€ëœ ì‚¬ê¸°: {len(detected_anomalies)}ê°œ")
        print(f"    Precision@{k}: {precision:.4f}")
        print(f"    Recall@{k}: {recall:.4f}")
    
    # Top 10 ìƒì„¸ ë¶„ì„
    print(f"\n[3] Top 10 ì´ìƒ ì§€ê°‘ ìƒì„¸ ë¶„ì„:")
    print("-"*70)
    top10 = results_df_sorted.head(10)
    
    for idx, (_, row) in enumerate(top10.iterrows(), 1):
        node = row['node']
        label = row['label']
        anomaly_score = row['anomaly_score']
        nts = row['nts']
        nws = row['nws']
        pattern_score = row['pattern_score']
        
        # PPR ì ìˆ˜ ê³„ì‚°
        first_source = list(full_ppr_scores.keys())[0]
        ppr_array, all_nodes_list = full_ppr_scores[first_source]
        node_to_idx = {node: idx for idx, node in enumerate(all_nodes_list)}
        
        ppr_sum = 0.0
        if node in node_to_idx:
            idx_pos = node_to_idx[node]
            for source, (ppr_arr, _) in full_ppr_scores.items():
                if idx_pos < len(ppr_arr):
                    ppr_sum += ppr_arr[idx_pos]
        
        label_str = "ğŸ”´ ì‚¬ê¸°" if label == 1 else "ğŸŸ¢ ì •ìƒ"
        
        print(f"\n  [{idx}] {node[:40]}...")
        print(f"      ë¼ë²¨: {label_str}")
        print(f"      Anomaly Score: {anomaly_score:.4f}")
        print(f"      êµ¬ì„±:")
        print(f"        - Ï€(vi) (PPR í•©ê³„): {ppr_sum:.6f}")
        print(f"        - F(Î¸,Ï‰)(vi) (íŒ¨í„´ ì ìˆ˜): {pattern_score:.6f}")
        print(f"        - NTS: {nts:.4f}")
        print(f"        - NWS: {nws:.4f}")
        
        # í”¼ì³ ê¸°ì—¬ë„ ë¶„ì„
        print(f"      í”¼ì³ ê¸°ì—¬ë„:")
        if pattern_score > 0:
            ppr_contribution = ppr_sum / pattern_score
            print(f"        - PPR ê¸°ì—¬: {ppr_sum:.6f}")
            print(f"        - íŒ¨í„´ ì ìˆ˜ ê¸°ì—¬: {pattern_score:.6f}")
            print(f"        - NTS ê¸°ì—¬: {nts:.4f}")
            print(f"        - NWS ê¸°ì—¬: {nws:.4f}")
    
    # í”¼ì³ í†µê³„
    print(f"\n[4] í”¼ì³ í†µê³„ (Anomaly vs Normal):")
    print("-"*70)
    
    anomaly_df = results_df[results_df['label'] == 1]
    normal_df = results_df[results_df['label'] == 0]
    
    print(f"\n  Anomaly ì§€ê°‘ (n={len(anomaly_df)}):")
    print(f"    í‰ê·  Anomaly Score: {anomaly_df['anomaly_score'].mean():.4f}")
    print(f"    í‰ê·  NTS: {anomaly_df['nts'].mean():.4f}")
    print(f"    í‰ê·  NWS: {anomaly_df['nws'].mean():.4f}")
    print(f"    í‰ê·  Pattern Score: {anomaly_df['pattern_score'].mean():.4f}")
    
    print(f"\n  Normal ì§€ê°‘ (n={len(normal_df)}):")
    print(f"    í‰ê·  Anomaly Score: {normal_df['anomaly_score'].mean():.4f}")
    print(f"    í‰ê·  NTS: {normal_df['nts'].mean():.4f}")
    print(f"    í‰ê·  NWS: {normal_df['nws'].mean():.4f}")
    print(f"    í‰ê·  Pattern Score: {normal_df['pattern_score'].mean():.4f}")
    
    print("\n" + "="*70)
    print("âœ… ìƒì„¸ ë¶„ì„ ì™„ë£Œ!")
    print("="*70)
    
    return detector, graph_obj, results_df_sorted


if __name__ == "__main__":
    detailed_analysis()

