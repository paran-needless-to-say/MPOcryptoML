"""
ìµœì¢… í•´ê²°ì±…: Etherscanì—ì„œ anomaly ì£¼ì†Œë“¤ì˜ ì‹¤ì œ ê±°ë˜ ê°€ì ¸ì˜¤ê¸°

ì „ëµ:
1. Kaggleì—ì„œ anomaly ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
2. í•´ë‹¹ ì£¼ì†Œë“¤ì˜ Etherscan ê±°ë˜ ìˆ˜ì§‘
3. ê·¸ë˜í”„ ìƒì„± + ì •í™•í•œ ë¼ë²¨
4. ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from graph import CryptoTransactionGraph
from kaggle_timestamp_matcher import get_timestamp_from_etherscan
from ppr import PersonalizedPageRank
from scoring import NormalizedScorer  
from anomaly_detector import MPOCryptoMLDetector
import pandas as pd
import numpy as np
import time


def main():
    print("="*70)
    print("ğŸ¯ Etherscan ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘")
    print("="*70)
    
    API_KEY = "TZ66JXC2M8WST154TM3111MBRRX7X7UAF9"
    
    # 1. Kaggleì—ì„œ anomaly ì£¼ì†Œë§Œ ê°€ì ¸ì˜¤ê¸°
    print("\n[Step 1] Loading Kaggle anomaly addresses...")
    kaggle_path = "./notebooks/ethereum-frauddetection-dataset/transaction_dataset.csv"
    df = pd.read_csv(kaggle_path)
    
    # FLAG=1ì¸ ì£¼ì†Œë“¤ (anomaly) - 1000ê°œë¡œ ìƒ˜í”Œë§
    print("\n  ğŸ“Š Sampling 1000 addresses...")
    n_total = 1000
    n_anomalies = int(n_total * 0.2)  # 20% anomaly
    n_normal = n_total - n_anomalies
    
    anomaly_addresses = df[df['FLAG'] == 1]['Address'].head(n_anomalies).tolist()
    normal_addresses = df[df['FLAG'] == 0]['Address'].head(n_normal).tolist()
    
    target_addresses = anomaly_addresses + normal_addresses
    
    print(f"  âœ“ Anomaly addresses: {len(anomaly_addresses)}")
    print(f"  âœ“ Normal addresses: {len(normal_addresses)}")
    print(f"  Total: {len(target_addresses)} addresses")
    
    # 2. Etherscanì—ì„œ ê±°ë˜ ìˆ˜ì§‘
    print("\n[Step 2] Fetching transactions from Etherscan...")
    print(f"  Processing {len(target_addresses)} addresses...")
    
    graph = CryptoTransactionGraph()
    
    labels = {}
    for i, address in enumerate(target_addresses):
        if (i + 1) % 5 == 0:
            print(f"  Progress: {i+1}/{len(target_addresses)}")
        
        txs = get_timestamp_from_etherscan(address, API_KEY)
        
        for from_addr, to_addr, value, timestamp in txs:
            graph.add_edge(from_addr, to_addr, value, timestamp)
        
        # ë¼ë²¨ ì„¤ì • (Known ë…¸ë“œë§Œ)
        if address in anomaly_addresses:
            labels[address] = 1  # Anomaly
        else:
            labels[address] = 0  # Normal (ì •ìƒ Known)
        
        # Unknown ë…¸ë“œëŠ” ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ!
        # â†’ ê±°ë˜ ìƒëŒ€ë°© ì¤‘ ì¼ë¶€ëŠ” Unknown
    
    # âœ… Weak Supervision êµ¬í˜„:
    # - Known: ì§ì ‘ ìˆ˜ì§‘í•œ ì£¼ì†Œë“¤ (ë¼ë²¨ ìˆìŒ)
    # - Unknown: ê±°ë˜ ìƒëŒ€ë°© (ë¼ë²¨ ì—†ìŒ)
    # - PPRì€ ì „ì²´ ë…¸ë“œì— ì ìš© (êµ¬ì¡° ì •ë³´ í™œìš©)
    # - LRì€ Knownë§Œ í•™ìŠµ (ë¼ë²¨ ìˆìŒ)
    
    graph.set_labels(labels)
    
    print(f"\nâœ“ Graph created:")
    print(f"  Nodes (V): {len(graph.nodes)}")
    print(f"  Edges (E): {len(graph.edges)}")
    print(f"  Labels: {sum(labels.values())} anomalies")
    
    # 2.5. ê·¸ë˜í”„ ì €ì¥
    from pathlib import Path
    Path("results").mkdir(exist_ok=True)
    
    graph.save("results/graph_200_etherscan_real.json")
    print(f"\n  ğŸ’¾ Graph saved to: results/graph_200_etherscan_real.json")
    
    # 3. ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
    print("\n[Step 3] Running algorithms...")
    
    nx_graph = graph.build_graph()
    ppr = PersonalizedPageRank(nx_graph, alpha=0.5, epsilon=0.01, p_f=1.0)
    
    source_nodes = ppr.get_source_nodes()
    if len(source_nodes) == 0:
        source_nodes = set(graph.nodes[:10])
    
    sample_nodes = list(source_nodes)[:min(10, len(source_nodes))]
    print(f"  Using {len(sample_nodes)} source nodes")
    
    ppr_results = {}
    ppr_scores = {}
    
    from tqdm import tqdm
    print(f"  Computing PPR for {len(sample_nodes)} source nodes...")
    
    for node in tqdm(sample_nodes, desc="  PPR", ncols=70):
        sps, svn, nodes_list = ppr.compute_single_source_ppr(node)
        ppr_results[node] = svn
        ppr_scores[node] = sps
    
    # NTS/NWS
    scorer = NormalizedScorer(graph, ppr_results)
    feature_scores = scorer.compute_all_scores()
    
    # Anomaly Detection
    full_ppr_scores = {}
    for node in graph.nodes:
        if node in ppr_scores:
            full_ppr_scores[node] = ppr_scores[node]
        else:
            full_ppr_scores[node] = np.zeros(len(graph.nodes))
    
    detector = MPOCryptoMLDetector(
        ppr_scores=full_ppr_scores,
        feature_scores=feature_scores,
        labels=labels
    )
    
    detector.train_logistic_regression()
    detector.compute_anomaly_scores()
    
    # ê²°ê³¼
    print("\n[Step 4] Results:")
    results_df = detector.get_results_df()
    results_df_sorted = results_df.sort_values('anomaly_score', ascending=False)
    
    print(f"\nTop 10 Anomaly Scores:")
    top10 = results_df_sorted.head(10)
    print(top10[['node', 'label', 'anomaly_score']])
    
    detected = top10[top10['label'] == 1]
    print(f"\nâœ… Detected {len(detected)} actual anomalies in top 10")
    
    # í‰ê°€
    for k in [5, 10]:
        eval_results = detector.evaluate_precision_at_k(k=k)
        print(f"\nPrecision@{k}: {eval_results.get(f'precision@{k}', 0):.4f}")
    
    print("\n" + "="*70)
    print("âœ… Completed successfully!")
    print("="*70)
    
    return detector, graph, results_df_sorted


if __name__ == "__main__":
    main()

